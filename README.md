AI-Interview-Maesterio

An end-to-end AI interviewer that conducts live technical/behavioral interviews, gives real-time nudges, and exports a concise PDF report with scores, strengths, and next steps.

Features

ğŸ™ï¸ Live interview: mic â†’ Whisper STT â†’ streaming transcript

ğŸ¤– LLM engine: dynamic questions, rubric scoring, actionable feedback

ğŸ¥ (optional) Camera analytics: OpenCV gaze/posture/filler-word heuristics

ğŸ“„ 1-click report: clean PDF with per-dimension breakdown

ğŸ”Œ Topic packs (DS/Algo, Python, Web, DB, ML basics) â€” easily extensible

ğŸ”’ Privacy-first: local processing by default; cloud LLMs opt-in

Architecture
Mic â†’ ffmpeg â†’ Whisper â†’ Transcript  â”€â”
                                      â”œâ”€> Orchestrator â†’ LLM (OpenAI/Groq/OpenRouter)
Camera â†’ OpenCV (optional) â†’ Signals â”€â”˜             â†“
Django + Channels (WebSockets) â†’ Live UI â† Scoring & Hints â†’ PDF Report

Tech Stack

Backend: Python 3.11+, Django 5, Channels/Daphne, Redis
AI/STT: OpenAI Whisper / Faster-Whisper, optional OpenCV
LLM: OpenAI / Groq / OpenRouter (OpenAI-compatible clients)
Build/Tools: ffmpeg, reportlab/weasyprint, pytest, ruff/black

Quickstart
Prerequisites

Python 3.11+

ffmpeg on PATH

(Optional) Redis for websockets scaling

Setup
git clone https://github.com/zohaibxkhan820/AI-Interview-Maesterio.git
cd AI-Interview-Maesterio

python -m venv .venv
# Windows
. .venv/Scripts/activate
# Linux/Mac: source .venv/bin/activate

pip install -r requirements.txt


Create .env in project root:

DJANGO_SECRET_KEY=change-me
DEBUG=True
ALLOWED_HOSTS=127.0.0.1,localhost

# LLM provider (choose one)
OPENAI_API_KEY=sk-****************

# Whisper model: tiny/base/small/medium/large (or faster-whisper path)
WHISPER_MODEL=small

# Optional Redis for Channels
REDIS_URL=redis://127.0.0.1:6379/0


Run migrations & server:

python manage.py migrate
daphne -b 0.0.0.0 -p 8000 config.asgi:application
# or: python manage.py runserver  (basic testing)


Open: http://localhost:8000

Usage

New Interview â†’ select role, topics, difficulty.

Allow microphone (and camera if OpenCV analytics enabled).

Answer questions; watch live transcript & soft-skill cues.

Finish â†’ Generate PDF report (stored in media/reports/).

Project Structure
ai-interview-maesterio/
â”œâ”€ config/                 # Django settings, ASGI/Channels routing
â”œâ”€ interview/
â”‚  â”œâ”€ api/                 # REST/WebSocket endpoints
â”‚  â”œâ”€ core/                # orchestration, scoring, prompts
â”‚  â”œâ”€ prompts/             # system prompts & topic packs
â”‚  â”œâ”€ reports/             # PDF generator
â”‚  â””â”€ vision/              # OpenCV heuristics (optional)
â”œâ”€ static/ templates/      # frontend assets
â”œâ”€ media/                  # transcripts, PDFs (gitignored)
â”œâ”€ requirements.txt
â””â”€ README.md

Scoring (defaults)

Technical 60% â†’ correctness, depth, code quality

Communication 25% â†’ clarity, structure, brevity

Delivery 15% â†’ confidence, pace, eye-contact/filler (if vision on)
Weights live in interview/core/scoring.py.

Configuration Notes

Switch LLM vendor via env only â€” all clients are OpenAI-compatible.

Add new topic packs by dropping YAML/JSON into interview/prompts/.

Reports

Output: media/reports/<SESSION_ID>.pdf with overall score, per-dimension chart, timeline, top-3 strengths, next-3 actions, and curated resources.

Tests & Quality
pytest -q
ruff check .  # or black/flake8

.gitignore (important)
# Python
.venv/ env/ venv/
__pycache__/ *.pyc

# Artifacts & large binaries
media/ reports/ *.pdf
*.pyd *.dll *.so *.dylib
*.pt *.bin *.onnx *.pkl

# Node
node_modules/
dist/ build/


Donâ€™t commit virtualenvs or >100MB files. Use Git LFS or Releases for large models.

Roadmap

 Preset interview tracks (SWE/DS/ML/Frontend)

 Panel interview mode

 Latency-optimized VAD pipeline

 Analytics dashboard for session trends

License

MIT â€” attribution appreciated.

Acknowledgements

OpenAI Whisper/Faster-Whisper, Django Channels, ffmpeg, OpenCV.
